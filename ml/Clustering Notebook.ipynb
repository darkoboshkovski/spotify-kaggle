{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.cluster import OPTICS, KMeans, DBSCAN, AffinityPropagation, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read dataframes containing records of songs, and also of artist so that we can extract genre for a specific song\n",
    "df = pd.read_csv(DATA_DIR / \"data.csv\")\n",
    "df_genres = pd.read_csv(DATA_DIR / \"data_w_genres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to filter out corrupt names and also remasters\n",
    "def is_corrupt(value: str) -> int:\n",
    "    found = bool(re.search(\"[0-9A-Za-z]\", value))\n",
    "    found = found and not \"remaster\" in value.lower() \n",
    "    return int(not found)\n",
    "\n",
    "#function for getting a genre for a specific song (heuristic)\n",
    "#uses only the last word in a genre name\n",
    "#gives priority to genres already present in the mapping\n",
    "genre_mappings = {}\n",
    "def get_genre(value: str) -> int:\n",
    "    for artist in value[1:-1].replace(\"'\", \"\").split(\",\"):\n",
    "        artist_genres = df_genres.loc[df_genres.artists == artist].genres.values\n",
    "#         print(artist_genres)\n",
    "        if artist_genres == \"[]\" or not artist_genres:\n",
    "            continue\n",
    "        artist_genres = artist_genres[0]\n",
    "        possible_candidates = artist_genres[1:-1].replace(\"'\", \"\").split(',')\n",
    "        last_suggestion = \"\"\n",
    "        inserting_new_genre = True\n",
    "        for candidate in possible_candidates:\n",
    "            last_suggestion = candidate.split(\" \")[-1]\n",
    "            if last_suggestion not in genre_mappings:\n",
    "                continue\n",
    "            else:\n",
    "                inserting_new_genre = False\n",
    "                break\n",
    "        if inserting_new_genre:\n",
    "            genre_mappings[last_suggestion] = len(genre_mappings)\n",
    "            \n",
    "        return genre_mappings[last_suggestion]\n",
    "    return -1\n",
    "\n",
    "# Filter out elements with corrupt artists/names fields\n",
    "# along with elements with unspecified artists\n",
    "df[\"artists_corrupt\"] = df[\"artists\"].apply(lambda x: is_corrupt(x))\n",
    "df[\"name_corrupt\"] = df[\"name\"].apply(lambda x: is_corrupt(x))\n",
    "df = df[df[\"artists_corrupt\"] == 0]\n",
    "df = df[df[\"name_corrupt\"] == 0]\n",
    "df = df[df[\"artists\"] != \"['Unspecified']\"]\n",
    "#Filter out elements with popularity of 0\n",
    "df = df[df[\"popularity\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out elements that are \"vocal only\", such as speeches etc.\n",
    "df = df[df[\"speechiness\"] < 0.66]\n",
    "# Filter by year (used to reduce the number of samples, because clustering is very slow otherwise)\n",
    "df = df[df[\"year\"] >= 2000]\n",
    "# There are some records of songs entered twice with different values for the features, removing them\n",
    "df = df.drop_duplicates([\"artists\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-partner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#random sample 10000 records (again, this is for performance reasons)\n",
    "#could be less in my opinion\n",
    "df = df.sample(10000)\n",
    "#insert genres into dataframe and remove songs with no genre\n",
    "df[\"genre\"] = df[\"artists\"].apply(lambda x: get_genre(x))\n",
    "df = df[df[\"genre\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe of the features needed for training\n",
    "df_feats = df.drop([\"artists\", \"name\", \"artists_corrupt\", \"name_corrupt\", \"id\",\n",
    "                    \"year\", \"release_date\", \"key\",\n",
    "                    \"instrumentalness\", \"popularity\", \"energy\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize features, each by its own column, and again the whole bunch\n",
    "#(this yielded the best results and also ensured all values have the same distribution)\n",
    "df_scaled_feats = normalize(df_feats, axis=0)\n",
    "df_scaled_feats = normalize(df_scaled_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-ready",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reduce dimensionality to 2 features (I also experimented with 3, but 2 seemed good enough)\n",
    "pca = PCA(n_components=2)\n",
    "df_pca_feats = pca.fit_transform(df_scaled_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-grenada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot the features in 2D\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(*[df_pca_feats[:,i] for i in range(2)], marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run KMeans Clustering\n",
    "#I experimented a lot with other clustering methods (OPTICS, DBScan, Agglomerative, etc.)\n",
    "#In the end KMeans turned out to give the best results, all factors considered\n",
    "cluster = KMeans(n_clusters=120)\n",
    "cluster.fit(df_pca_feats)\n",
    "df[\"clusters\"] = cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the silhouette score for our clustering\n",
    "score = silhouette_score(df_pca_feats, cluster.labels_, metric='euclidean')\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialized features to check when analysing clusters\n",
    "CHECK_FEATS = [\"acousticness\", \"danceability\", \"liveness\",  \"loudness\", \"genre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a dataframe of the scaled_feats (the normalization turns it into numpy)\n",
    "df_scaled_feats = pd.DataFrame(df_scaled_feats, columns=df_feats.columns.tolist())\n",
    "df_scaled_feats.index = df_feats.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get min and max values across all features we are interested in\n",
    "max_values = {feat: df_scaled_feats[feat].max() for feat in CHECK_FEATS}\n",
    "min_values = {feat: df_scaled_feats[feat].min() for feat in CHECK_FEATS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyse clusters\n",
    "#random choice of 50 clusters is analyzed for features that have lowest standard deviation (3 of them)\n",
    "#after selecting 10 of those, the process terminates\n",
    "#it also provides 30 songs from the cluster with name, artist name, min, max values for the features along with their means.\n",
    "cluster_info = {}\n",
    "for cluster_idx, cluster in enumerate(np.random.choice(df[\"clusters\"].unique(), min(len(df[\"clusters\"].unique()), 50))):\n",
    "    if len(cluster_info) > 10:\n",
    "        break\n",
    "    cluster_df = df[df[\"clusters\"] == int(cluster)]\n",
    "    idxs = df[df[\"clusters\"] == int(cluster)].sample(min(len(cluster_df), 30)).index\n",
    "    df_feats_chunk = df_scaled_feats.loc[idxs]\n",
    "    chunk_stds = []\n",
    "    chunk_means = []\n",
    "\n",
    "    for feat in CHECK_FEATS:\n",
    "        chunk_means.append(df_feats_chunk[feat].mean())\n",
    "        chunk_stds.append(df_feats_chunk[feat].std())\n",
    "\n",
    "    chunk_stds = np.asarray(chunk_stds)\n",
    "    chunk_means = np.asarray(chunk_means)\n",
    "\n",
    "    argsorted = np.argsort(chunk_stds)\n",
    "    chunk_stds = chunk_stds[argsorted]\n",
    "    chunk_means = chunk_means[argsorted]\n",
    "\n",
    "    chunk_stds = list(chunk_stds)\n",
    "    chunk_means = list(chunk_means)\n",
    "    \n",
    "    feat_names = [CHECK_FEATS[i] for i in argsorted[:3]]\n",
    "    song_names = cluster_df.loc[idxs].name.values.tolist()\n",
    "    artist_names = cluster_df.loc[idxs].artists.apply(lambda x: x[1:-1].replace(\"'\", \"\").replace(\", \", \",\").split(\",\")).values.tolist()\n",
    "    cluster_info[cluster_idx] = {\"feats\": feat_names, \"means\": chunk_means[:3],\n",
    "                             \"mins\":[min_values[feat] for feat in feat_names],\n",
    "                             \"maxes\": [max_values[feat] for feat in feat_names],\n",
    "                              \"song_names\": song_names, \"artists\": artist_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-demonstration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
